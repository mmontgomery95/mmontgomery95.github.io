---
layout: post
title: Local Environments and Beautifulsoup
date: 2020-02-14
---


__Local Environments__
```
python3 -m venv my_env
```
Creates a local programming environment

```
source my_env/bin/activate
```
Activates and enters the local environment `my_env`. From here, files can be written to execute code 
as you would within any other compiler.


**Beautifulsoup** is a program used for scraping webpages; using the `.find_all(ARG)` command allows you 
to search a webpage for every instance of an argument, such as `<p>`, `class`, and `id`.
Using this with the local environment allows the user to instantly pass arguments and receive results, making it much easier to search through a webpage.

Webscraping is at its core an organizational logic puzzle; getting desired results means finding within a page's source code each unique tag to narrow down where the target information is located. Depending on the amount of information desired, and the layout of the page, this could mean any number of nested tags before reaching the actual data. 

Once the correct data is received, it then is formatted to be displayed. For my purposes, I put my data into a .csv file. In my sample .csv, I took a webpage with a list of Texas counties. Once I pared down the retrieved data to contain only the string with the county name, county seat, and link to information, I separated out the string using `split(",")` to separate into multiple strings wherever a comma was, and then `strip()` to remove whitespace. This gave me the ability to pull multiple data points from a single string.

